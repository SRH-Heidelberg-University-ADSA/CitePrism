{
  "metadata": {
    "title": "Materials Today Communications",
    "authors": [
      {
        "name": "Loai Alkhattabi a",
        "affiliation": "",
        "email": ""
      },
      {
        "name": "Kiran Arif b",
        "affiliation": "",
        "email": ""
      },
      {
        "name": "c",
        "affiliation": "",
        "email": ""
      },
      {
        "name": "*",
        "affiliation": "",
        "email": ""
      }
    ],
    "journal": "journal homepage: www.elsevier.com/locate/mtcomm",
    "year": null,
    "doi": "",
    "received_date": "27 April 2024",
    "accepted_date": "4 July 2024",
    "available_online": "9 July 2024"
  },
  "abstract": "Novel base predictive model of resilient modulus of compacted subgrade soils by using interpretable approaches with graphical user interface Loai Alkhattabi a , Kiran Arif b , c , * a Department of Civil and Environmental Engineering, College of Engineering, University of Jeddah, Jeddah 23890, Saudi Arabia b Department of Computer Science, COMSATS University Islamabad, Wah Campus, Islamabad 47040, Pakistan c Western Caspian University, Baku, Azerbaijan A R T I C L E I N F O Keywords: Resilient modulus Subgrade Graphical user interface Machine learning Statistical measures A B S T R A C T The flexible pavement system consists of layers that are made up of a blend of aggregates and bitumen. To design flexible pavement systems that are both safe and environmentally sustainable, it is essential to have an accurate understanding of the resilient modulus (M r ) of the compacted subgrade soil. M r refers to the ability of the soil to",
  "keywords": [
    "Loai Alkhattabi a",
    "Kiran Arif b",
    "c",
    "*"
  ],
  "sections": [
    {
      "title": "soils by using interpretable approaches with graphical user interface",
      "content": "Loai Alkhattabi a , Kiran Arif b , c , * a Department of Civil and Environmental Engineering, College of Engineering, University of Jeddah, Jeddah 23890, Saudi Arabia b Department of Computer Science, COMSATS University Islamabad, Wah Campus, Islamabad 47040, Pakistan c Western Caspian University, Baku, Azerbaijan A R T I C L E I N F O",
      "start_page": 0,
      "end_page": 0
    },
    {
      "title": "Keywords:",
      "content": "Resilient modulus Subgrade Graphical user interface Machine learning Statistical measures A B S T R A C T The flexible pavement system consists of layers that are made up of a blend of aggregates and bitumen. To design flexible pavement systems that are both safe and environmentally sustainable, it is essential to have an accurate understanding of the resilient modulus (M r ) of the compacted subgrade soil. M r refers to the ability of the soil to resist deformation under repeated loads. Thus, a critical parameter affects the performance and longevity of pavement systems. This study employs machine learning (ML) algorithms such as individual and ensemble learners using an extensive database of 2813 data points. These include dry unit weight, weighted plasticity index, confining stress, deviator stress, moisture content, and the number of freeze-thaw cycles (FT). The indi- vidual or weak learners were incorporated to create strong and robust ensemble learners by employing tech-",
      "start_page": 0,
      "end_page": 0
    },
    {
      "title": "niques such as bagging, adaptive boosting, and random forest (RF). Ensemble learning methods were used to",
      "content": "improve the performance of individual learners, such as support vector machine (SVM) and decision tree (DT), by combining their predictions. To achieve the highest R 2 value, a total of twenty bagging and boosting sub- models were trained and optimized. The validation of the test data was carried out through K-Fold cross- validation, utilizing metrics such as R 2 , MAE, and RMSE. The developed models were rigorously tested using statistical indices (MAE, MSE, RMSE, and RMLSE) to verify their predictive accuracy, reliability, and trustwor- thiness. The findings indicate that the integration of bagging and boosting techniques improves the efficiency of individual machine learning (ML) models. The combination of RF and DT utilizing bagging resulted in the most reliable performance, achieving an R 2 value of 0.9 and demonstrating minimum errors. In general, the imple- mentation of the ensemble algorithm in ML improved the overall prediction accuracy of the model. Sensitivity analysis reveals that the prediction of the resilient modulus (M r ) of the subgrade is primarily influenced by dry density, confining stress, and deviator stress. Moreover, a graphical user interface (GUI) is developed for practical implantation.",
      "start_page": 0,
      "end_page": 0
    },
    {
      "title": "1. Introduction",
      "content": "The pavement system consists of several layers having different material properties. These layers typically include the surface, base, subbase, and subgrade [1 – 3] . The strength and stiffness of these layers play an important role in designing the pavement system [4 – 6] . The subgrade layer is called the foundation of the pavement system [7] . It transfers applied loads to the ground. However, seasonal fluctuations and cyclic or dynamic loads on pavement layers cause stresses in these layers [8] . Moreover, the primary support for all pavements is due to the underlying subgrade layer. This layer typically consists of varying soil combinations is considered as the fundamental base of the pavement structure, and is responsible for transferring applied loads to the ground [9] . Thus, resilient modulus (M r ) serves as a vital parameter for assessing subgrade material ’ s behaviour under various environmental and load conditions [10 – 13] . Additionally, it explains the material ’ s inelastic response to traffic loads. As pavement layers endure repetitive traffic loads, the subgrade soil undergoes both reversible and irreversible strains with each load cycle [12] . With an increasing number of load repetitions, the extent of plastic deformation diminishes until it becomes recoverable. Therefore, M r is defined as the ratio of the applied deviator stress to the recoverable strain. This ratio serves as a descriptor for the * Corresponding author. E-mail addresses: laalkhattabi@uj.edu.sa (L. Alkhattabi), kiranarif12345@gmail.com (K. Arif). Contents lists available at ScienceDirect",
      "start_page": 0,
      "end_page": 0
    },
    {
      "title": "Materials Today Communications",
      "content": "journal homepage: www.elsevier.com/locate/mtcomm https://doi.org/10.1016/j.mtcomm.2024.109764 Received 27 April 2024; Received in revised form 18 June 2024; Accepted 4 July 2024 Materials Today Communications 40 (2024) 109764 Available online 9 July 2024 2352-4928/© 2024 Elsevier Ltd. All rights are reserved, including those for text and data mining, AI training, and similar technologies. material ’ s behaviour, providing insights into its deformation and re- covery characteristics under stress. The M r of the soil has a direct rela- tionship with both fatigue cracking and permanent deformation. Hence, considered an essential property for understanding pavement behaviour and its design [14 – 17] . The M r of compacted pavement subgrade soils depends upon mul- tiple factors. These factors encompass a range of characteristics and conditions that affect the soil ’ s ability to withstand and recover from applied loads [12] . Some key factors include the soil ’ s composition, density, moisture content, stress history, temperature, and loading fre- quency [18 – 20] . Each of these factors contributes to the overall resilient modulus of the subgrade soils and plays a significant role in determining their response to traffic loading and subsequent pavement performance [21] . Moreover, the seasonal environmental effects are also important in regions with seasonal freezing. Typically, subgrade soils are compacted at their maximum dry unit weight and optimal moisture content. The moisture content can vary seasonally due to environmental factors, such as precipitation, surface infiltration, plant transpiration, evaporation, temperature fluctuation, and groundwater table variation [22 – 24] . In regions where seasonal freezing occurs, FT cycles can cause substantial harm to pavements. Thus, resulting in pavement surface spalling and cracking [25] . This can also lead to severe settlement caused by the influx of water during the spring thaw. These issues stem from the decline in subgrade soil strength and stiffness, as well as an increase in water content caused by FT. The M r and strength of pavement materials",
      "start_page": 0,
      "end_page": 1
    },
    {
      "title": "degrade during FT processes. This results in a significant increase in",
      "content": "tensile strain on the surface layer of the pavement when subjected to traffic loading [26] . Moreover, the increase in tensile strain can cause fatigue cracks to form on the pavement surface, which can lead to further damage if left unaddressed. Thus, permanent deformation can develop, resulting in rutting of the pavement. Furthermore, when pavement materials experience desiccation (drying out) and thermal shrinkage (reduction in volume due to tem- perature changes), longitudinal and transverse cracks may appear. The M r refers to a measure of the elastic modulus (EM) that defines the non- linear stress-strain properties of subgrade materials. This is an important factor in the structural response of pavements [27 – 30] . M r considers the effects of various stress states, including traffic loading, confining stress, cyclic stress, and deviator stress. In addition, M r can be determined",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "through various laboratory testing methods, which include in-situ",
      "content": "testing, cyclic tri-axial load testing, resonant column testing, and torsional shear testing [31 – 33] . Despite their effectiveness, these",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "methods are expensive and complex. Nevertheless, incorporating M r in",
      "content": "the design and structural analysis of multi-layer pavement systems has been recommended by various codes, including ME PDG, AASHTO, and NCHRP. Moreover, it is imperative to consider multiple properties of the materials in the unbound layers for describing the resilient behaviour of pavement, including several soil hydrological and physical characteris- tics. Thus, it is critical to gain an accurate understanding of the factors that precisely affect M r . As a result, many studies have been conducted that led to the proposal of several constitutive models that estimate M r of soil properties, applied loads, and stress states. Typically, these models are developed using regression analysis, as demonstrated in Table 1 . It provides a collection of equations that are used for the estimation of the M r of soils. These equations rely on key variables influenced by different stress states, such as σ 2 and σ 3 , which vary across soil samples. These stress states vary among soil samples in the laboratory and play a crucial role in the determination of the updated M r value for each soil sample. The values of k 1 , k 2 , and k 3 are obtained by fitting the prediction model to the laboratory-generated M r test data, using either linear or nonlinear regression analyses. It is important to note that k 1 cannot be negative, as M r cannot have negative values. On the other hand, k 2 should always be",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "positive, as an increase in the confining stress typically results in a",
      "content": "stiffening effect on the material. This will lead to a higher value for M r . Conversely, k 3 must be negative, as an increase in deviator or shear",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "stress results in a softening effect on the material. Finally, a second set of",
      "content": "regression analyses is conducted to establish the relationship between these k-coefficients and various soil physical properties, such as mois- ture content, dry density, plasticity index, liquid limit, coefficient of curvature, uniformity coefficient, and percent passing #200 sieve [37 – 39] . The details on how these models are obtained can be found in previously published literature. Moreover, it is clear that the afore- mentioned analysis method is complex, and there are other drawbacks to using regression analysis. Although the model developed through regression, analysis performs well on selected data sets. Therefore, its effectiveness is limited to the range of datasets used in the analysis. Additionally, existing models lack validation and testing on new data [40 – 42] . Given the shortcomings of these models and the intricate behaviour of M r , there is a need to develop more effective prediction models for estimating M r in pavement subgrade soils. Several re- searchers have used traditional linear and nonlinear equations based on statistical analysis to provide prediction measures of resilient modulus. However, accurate prediction is difficult, and more research is required to overcome these challenges. In recent years, neural-based ML tech- niques have been used to overcome challenges and improve the accu- racy of predictions in various applications. [43 – 52] . The use of ML techniques is becoming increasingly popular in civil engineering, particularly in the prediction of mechanical properties of materials like concrete, asphalt, and resilient modulus (M r ) value",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "[53 – 60] . These methods rely heavily on extensive datasets to build ac-",
      "content": "curate models. The success of these models is contingent upon both the quality and quantity of the data used during the model development process [61 – 63] . In other words, having a substantial and high-quality",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "dataset is crucial for the effectiveness of these ML methods [64 – 68] .",
      "content": "Javed et al. [47] utilized gene expression programming (GEP) to forecast the compressive strength (CS) of sugarcane bagasse ash (SCBA) con- crete. Likewise, Aslam et al. [46] used the GEP approach to predict the strength of high-strength concrete (HSC). Their findings indicated a strong correlation between the predicted values and target values. In addition, researchers have employed artificial neural networks (ANNs) to forecast the strength of concrete made of waste and recycled mate- rials, and their finding reveals that ANNs have shown a strong rela- tionship with fewer errors [69] . Zaman et al. [70] conducted a study exploring the construction of different ANNs. The goal was to establish a relationship between M r and standard subgrade soil characteristics, along with stress states encountered in pavement design. Similarly, Zou et al. [71] employed GEP and ANNs for the estimation of compressed",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "subgrade soils and reported robust results. Deswal and Pal [72] evalu-",
      "content": "ated the performance of two machine-based extreme learning regression models for calculating the resilient modulus (M r ) of cohesive soils. The",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "author compared their results with those obtained from SVM methods",
      "content": "and demonstrated a robust performance by these models. In addition, Sadrossadat et al. [73] used a neuro-fuzzy adaptive interface system to forecast the behaviour of subgrade soils in flexible pavements. ML",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "Table 1",
      "content": "Equations for predicting resilient modulus (M r ) of soils through generalized regression.",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "Equation",
      "content": "Kim [34] A-4 and A-6 soils M r P a = k 1 [ P a . σ oct τ 2 oct ] k 2 A-7 – 6 soils M R = k 1 . P a [",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "9 P a",
      "content": "2 ( 1",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "3 σ d",
      "content": "+ σ 3 σ 2 d ) ] k 2 Universal model [34,35] All types of soils M R = k 1 . P a ( θ P a ) k 2 ( τ oct P a + 1 ) k 3 Pezo and Hudson [36] Fine grain materials M R = k 1 σ k 2",
      "start_page": 1,
      "end_page": 1
    },
    {
      "title": "3 σ k 3",
      "content": "d M r = resilient modulus; P a = atmosphere pressure; σ oct = octahedral normal stress k 1 = regression coefficients τ oct = octahedral shear stress θ = bulk stress σ d = deviator stress k 2 & k 3 = regression coefficients L. Alkhattabi and K. Arif Materials Today Communications 40 (2024) 109764 2 Fig. 1. MLA Bibliometric Analysis. Fig. 2. Comparison between approaches. L. Alkhattabi and K. Arif Materials Today Communications 40 (2024) 109764 3 algorithms are versatile tools that can be utilized to predict a range of responses in various engineering or data science fields, beyond the compressive or tensile nature of concrete. These examples highlight the promising potential of ML algorithms in various domains. Moreover, the significance of MLAs in civil engineering domain is illustrate in Fig. 1 . Recently, there has been an increasing inclination towards the",
      "start_page": 1,
      "end_page": 3
    },
    {
      "title": "adoption of ensemble modelling methods to improve the overall effec-",
      "content": "tiveness of models. This is achieved by combining individual or weak learners to build much stronger predictive learners [74] . Feng et al. [75] used ensemble learning techniques to predict the properties of rein- forced concrete (RC) structural elements and observed a strong and robust performance of the models. Bui et al. [76] also used a modified firefly algorithm in combination with an ANN to forecast the behaviour",
      "start_page": 3,
      "end_page": 3
    },
    {
      "title": "of high-performance concrete (HPC). The results indicate that the hybrid",
      "content": "model performed better and gave a strong performance. Similarly, Salami et al. [77] utilized the RF approach and achieved a good accuracy of R 2 = 0.9867. Cai et al. [78] predicted the penetration of chloride in RC structures located in marine environment using several supervised machine ensemble algorithms. Halil et al. [58] applied three ensemble modelling techniques, using a decision tree (DT) as the base learner. The hybrid model demonstrated superior predictive performance for HPC strength compared to other models, resulting in a robust R 2 value of 0.9368. In a study conducted by Kermani et al. [59] , the efficiency of five soft computing base learners was systematically assessed with the aim of predicting concrete corro- sion in sewer systems. The study incorporated both tree-based and network-based learners. The notable outcome was the superior perfor- mance of Random Forest (RF) ensemble learners compared to the other models under consideration, demonstrating a substantial R 2 value of 0.872. This suggests that ensemble modelling approaches, such as RF, demonstrated enhanced impact and robust performance in predicting concrete corrosion. The study indicates that ensemble learning models, which combine multiple models, exhibit more desirable characteristics",
      "start_page": 3,
      "end_page": 3
    },
    {
      "title": "and yield superior results compared to individual learning models. This",
      "content": "is further illustrated in Fig. 2 , highlighting the distinction between in- dividual and ensemble models. Complex real-world challenges often necessitate the presence of intelligent systems that exhibit human-like expertise within a particular domain. These systems should also possess the capability to adapt to dynamic environments and provide explanations regarding their decision-making processes and actions. The objective of this study is to evaluate the accuracy of predicting resilient modulus (M r ) of compacted subgrade by employing different techniques, including individual and ensemble approaches. To accomplish this, data points from the literature were utilized. The programming tools used for modelling were Anaconda Spyder and Jupyter Notebook. The model parameters included weighted plasticity index, confining stress, dry unit weight, deviator stress, moisture content, and the number of FT cycles, with M r as the output parameter. Contour graphs were generated to demonstrate the correlation between input and output parameters. Moreover, this study has made a notable contribution to the advancement of a novel",
      "start_page": 3,
      "end_page": 3
    },
    {
      "title": "and efficient methodology for predicting the resilient modulus. By",
      "content": "introducing a potential pathway in the form of a graphical user interface (GUI), integrated strategies within the field of transportation can be effectively utilized. Additionally, Shapley analysis was employed to determine the effectiveness of each variable in achieving the desired output. Furthermore, statistical metrics were employed to assess the accuracy of the model.",
      "start_page": 3,
      "end_page": 3
    },
    {
      "title": "2. Data description",
      "content": "Data description is an important step in the process of building machine-learning models [79] . It involves thoroughly understanding the dataset and its characteristics before delving into the modelling phase. Thus, the M r of compacted subgrade soil has been modelled using data obtained from previously published research ( Supplementary file ). Furthermore, instances (data points) used for modelling will have higher reliability and accuracy of the model. The database consisted of a total of",
      "start_page": 3,
      "end_page": 3
    },
    {
      "title": "2813 experimental test results with resilient modulus as the response",
      "content": "parameter and six explanatory variables namely as the weighted plas- ticity index (wPI), deviator stress ( σ d in kPa), moisture content (w in %), dry unit weight ( γ d in kN/m 3 ), the number of FT cycles (N FT ), and confining stress ( σ c in kPa). 2.1. Database presentation Python programming based on Anaconda version 3.7 was employed to represent the database and the relation of input parameters to its output model. Fig. 3 represents the heat map correlations between the resilient modulus and the input variables. It can be seen that γ d shows direct and positive relation to M r . A higher dry unit weight indicates a denser and more compacted subgrade, which tends to exhibit higher stiffness and load-bearing capacity. However, moisture content and the number of FT cycles have adverse effects. This is because excess mois- ture softens the subgrade, reduces cohesion, and induces swelling or shrinkage, while FT cycles cause frost heave, thaw weakening, and cracking as illustrated in Fig. 3 . Moreover, Fig. 4 depicts the distribution of input parameters and their corresponding outputs, illustrating their relationship. The contour graphs depict the density of each input parameter concerning M r , with darker regions indicating a higher concentration linked to concrete strength in the database. The weighted plasticity index ranges from 5.82 to 31.08, with mean and median values around",
      "start_page": 3,
      "end_page": 3
    },
    {
      "title": "0 KPa to 41.4 KPa, representing extremes in the dataset. Analyzing the",
      "content": "distribution of explanatory variables aids in constructing a generalized model [40] . The dataset ’ s highest and lowest values illustrate its ex- tremes, while mean, median, and mode serve as indicators of central tendencies. Standard deviation (SD) measures data variability, with a smaller SD indicating a more concentrated distribution and a larger SD suggesting a broader and potentially more diverse distribution. This statistical metric provides insights into the spread or dispersion of data points, aiding in the understanding of the data ’ s overall distribution pattern. Skewness and kurtosis evaluate normal probability distribution regularity and profile [61] . Skewness is a statistical metric used to evaluate the asymmetry within a probability distribution, with zero suggesting perfect symmetry, positive values indicating a longer right tail, and negative values a longer left tail. Kurtosis serves as a statistical metric characterizing the form of a probability distribution or the extent of \"tailedness\" in the distribution curve of a dataset. Positive kurtosis (leptokurtic) and zero kurtosis Fig. 3. Heat map correlation. L. Alkhattabi and K. Arif Materials Today Communications 40 (2024) 109764 4 (mesokurtic) are characteristics associated with a normal distribution, signifying a certain level of peakedness in the distribution curve. Posi- tive kurtosis (leptokurtic) suggests a more peaked curve, indicating heavier tails and a distribution with more extreme values than a normal distribution. In contrast, negative kurtosis (platykurtic) suggests a flatter data curve, indicating a distribution with lighter tails compared to a normal distribution [62] . Understanding kurtosis provides valuable in- sights into the shape and tails of a probability distribution, contributing to a comprehensive analysis of the data ’ s characteristics. Table 2 shows that selected inputs and outputs align with suggested skewness and Fig. 4. Relation of parameters to resilient modulus; (a) weighted plasticity index; (b) dry unit weight; (c) confining stress; (d) deviator stress; (e) moisture content; (f) number of FT cycles.",
      "start_page": 3,
      "end_page": 4
    },
    {
      "title": "Table 2",
      "content": "Data Statistics for Model Development. wPI",
      "start_page": 4,
      "end_page": 4
    },
    {
      "title": "γ d",
      "content": "(kN/m 3 )",
      "start_page": 4,
      "end_page": 4
    },
    {
      "title": "σ c",
      "content": "(kPa)",
      "start_page": 4,
      "end_page": 4
    },
    {
      "title": "σ d",
      "content": "(kPa) w (%) N FT count 2813.00 2813.00 2813.00 2813.00 2813.00 2813.00 mean 13.88 17.73 27.17 45.64 18.36 4.13 std 6.43 1.56 11.85 17.34 4.52 3.93 min 5.82 15.50 0.00 13.80 12.30 0.00",
      "start_page": 4,
      "end_page": 4
    },
    {
      "title": "25 %",
      "content": "8.28 16.16 13.80 27.60 13.90 1.00",
      "start_page": 4,
      "end_page": 4
    },
    {
      "title": "50 %",
      "content": "13.16 17.77 27.60 41.40 17.30 3.00",
      "start_page": 4,
      "end_page": 4
    },
    {
      "title": "75 %",
      "content": "19.58 19.15 41.40 55.20 23.10 6.00 Standard error 0.12 0.029 0.22 0.32 0.08 0.07 Sample Variance 41.40 2.42 140.4 300.6 20.4 15.4 Kurtosis 0.00 -1.5 -1.19 -1.11 -0.99 1.9 Skewness 0.71 0.08 -0.14 -0.13 0.35 1.20 Range 25.26 4.9 41.4 55.1 29.2 20 max 31.08 20.40 41.40 68.90 41.54 20.00",
      "start_page": 4,
      "end_page": 4
    },
    {
      "title": "Table 3",
      "content": "Pearson Correlation Matrix for Utilized Data in Models.",
      "start_page": 4,
      "end_page": 4
    },
    {
      "title": "M r (MPa)",
      "content": "wPI 1 γ d (kN/m 3 ) -0.37589 1 σ c (kPa) -0.04884 -0.08613 1 σ d (kPa) -0.07923 0.03045 0.01414 1 W (%) 0.51245 -0.90425 0.05001 -0.03178 1 N FT 0.02234 0.02995 -0.01262 6.72759E-4 0.00606 1 M r (MPa) -0.02486 0.26998 0.03292 -0.11429 -0.35437 -0.32427 1 L. Alkhattabi and K. Arif Materials Today Communications 40 (2024) 109764 5 kurtosis ranges, enhancing data distribution. Table 3 represents the Pearson correlation coefficient (r), an important statistic in the context of artificial intelligence (AI) modeling. This coefficient quantifies the correlation between input and output variables, shedding light on the strength of their association. Ranging from − 1 – 1, a value of 0 indicates no correlation, while − 1 and + 1 signify strong negative and positive correlations, respectively. The correlation matrices in Table 3 show a strong connection, without the issue of multi-collinearity. It ’ s crucial to",
      "start_page": 4,
      "end_page": 5
    },
    {
      "title": "note that in this study, AI methods successfully handle multi-collinearity",
      "content": "when modeling M r . Python programming, along with Seaborn, is employed to implement ML algorithms and generate graphs. It provides a clearer understanding of how changes in input variables relate to changes in output strength, which ultimately helps in making pre- dictions about the mechanical behavior of a system.",
      "start_page": 5,
      "end_page": 5
    },
    {
      "title": "3. Methodology",
      "content": "Currently, numerous industries utilizes machine-learning algorithms (MLAs) to understand and estimate material behaviour [80 – 84] . In this research, various ML-based approaches, namely support vector ma- chines (SVM), decision trees (DT), and random forests (RF), are employed to assess the resilient modules (M r ) of subgrade. These particular techniques were chosen due to their widespread application [85 – 87] . Moreover, the rationale behind in selecting these approaches was driven by their distinctive advantages in handling the complexities. DT approach has ability to model non-linear relationship and interpret interaction. Similarly, RF improves prediction accuracy by aggregating multiple decision trees, and SVR capturing intricate non-linear patterns using kernel functions, making it adaptable to the diverse complex na- ture. The addition of ensemble benefits the models by variance reduc- tion, model stability, predicative accuracy, effective handling of non- linear relationship, and robust and adaptability. Thus, their use proves",
      "start_page": 5,
      "end_page": 5
    },
    {
      "title": "accuracy in predicting results in similar studies, and recognized effi-",
      "content": "ciency. Moreover, an ensemble learning technique (ELT) is implemented to forecast the strength of M r . The ensemble learning method combines the predictions from multiple ML models to enhance overall prediction performance [88] . Fig. 5 depicts the comprehensive flow diagram of the ML algorithm process that is used in our research.",
      "start_page": 5,
      "end_page": 5
    },
    {
      "title": "4. Machine learning (ML) methods",
      "content": "4.1. ML Using SVR algorithm The support vector regression (SVR) technique was first introduced by Vapnik in 1995 [89] . Since then, it has gained widespread use for performing classification, prediction, and regression tasks. Numerous studies have demonstrated the high learning capacity of SVMs in civil and structural engineering [90 – 92] . The approach utilizes labelled training data to generate support vector machines (SVMs). SVMs can be utilized for either binary classification, where there are two possible Fig. 5. Research flow chart with details used in making models. L. Alkhattabi and K. Arif Materials Today Communications 40 (2024) 109764 6 outcomes (0 and 1), or for regression tasks, where the goal is to predict a continuous actual value. Given its proficiency in effectively addressing nonlinear regression challenges, the SVM regression model is frequently employed in input-output analysis. The first step in SVM regression in- volves mapping the data to an n-dimensional function space in a fixed manner. Nonlinear activation functions are subsequently applied to transform the input data into a more powerful space, creating a clear distinction from the initial space. The expression f(x, w) is employed to denote the linear function within this transformed space. f ( x , w ) = ∑ n j = 1 w j g j ( x ) + b (1) In SVM regression, the function \"gj(x)\" is employed to express the transformations of the nonlinear input space, the bias term \"b,\" and the weight vector \"w\". The primary aim is to acquire optimal values for these parameters by maximizing the regularized risk function. This function considers the delicate balance between model accuracy and decision boundary complexity, making it a crucial aspect of achieving an effec- tive and well-balanced model. The estimate ’ s quality can also be measured using the loss function L, which can be expressed as follows. L ε = L ε ( y , f ( x , w ) ) = { 0 | y − f ( x , w ) | if | y − f ( x , w ) ≤ ε otherwise (2) SVM regression is unique in its ability to accommodate a variety of loss functions, which enables the creation of a linear regression function with an extensive feature set while simultaneously reducing model complexity by minimizing |(|w|)|2. This feature provides data scientists with a double benefit. The function uses nonnegative slack variables, denoted by ξ i + ξ i^*, where I = 1, … ,n represents the samples present in the π -insensitive area. This simplifies the function as follows, leading to the construction of SVM regression: min 1 2 || w | | 2 + C ∑ n i = 1 ( ξ i + ξ ∗ i ) (3) subject to ⎧ ⎪ ⎪ ⎨ ⎪ ⎪ ⎩ y i − f ( x i , w ) ≤ ε + ξ ∗ i f ( x i , w ) − y i ≤ ε + ξ ∗ i ξ i , ξ ∗ i ≥ 0 , i = 1 , … , n (4) The optimization problem can be rephrased as a dual problem, and it can be addressed utilizing the following function. f ( x ) = ∑ nsv i = 1 ( α i + α ∗ i ) K ( x , x i ) subject to0 ≤ α ∗ i ≤ C , 0 ≤ α i ≤ C (5) where n SV represents the number of support vectors. The kernel function is expressed as follows: K ( x , x i ) = ∑ m i = 1 ( g i ( x ) + g i ( x i )) (6) Fig. 6. SVM representation. Fig. 7. DT schematic diagram. Fig. 8. RF algorithm schematic diagram.",
      "start_page": 5,
      "end_page": 6
    },
    {
      "title": "Table 4",
      "content": "Hyper parameters and their values used in constructing models.",
      "start_page": 6,
      "end_page": 6
    },
    {
      "title": "Optimal",
      "content": "Decision Tree min samples split",
      "start_page": 6,
      "end_page": 6
    },
    {
      "title": "2 – 5",
      "content": "4 max depth none, 1 – 5 None min samples leaf",
      "start_page": 6,
      "end_page": 6
    },
    {
      "title": "1 – 5",
      "content": "3 max features auto, sqrt auto Support Vector Regression Gamma 0.5, 0.1, 0.01 0.5 Kernel Linear, rbf, poly, sigmoid rbf C",
      "start_page": 6,
      "end_page": 6
    },
    {
      "title": "1 – 2500",
      "content": "2250 Random Forest min samples leaf",
      "start_page": 6,
      "end_page": 6
    },
    {
      "title": "1 – 5",
      "content": "1 min samples split",
      "start_page": 6,
      "end_page": 6
    },
    {
      "title": "2 – 5",
      "content": "2 max depth none, 1 – 5 None n estimators",
      "start_page": 6,
      "end_page": 6
    },
    {
      "title": "20 – 200",
      "content": "60 max features auto, sqrt Auto Bootstrap true, false True L. Alkhattabi and K. Arif Materials Today Communications 40 (2024) 109764 7 Various mathematical functions, including linear, radial basis, polynomial, or sigmoid functions, are employed during the training of SVM to detect support vectors on the function surface. The selection of the kernel function plays a crucial role in determining the complexity and flexibility of the decision boundary created by the SVM model [93] . Each kernel function has unique properties and is appropriate for different types of data, depending on the data set ’ s specific character- istics and the modelling task ’ s requirements. Moreover, Fig. 6 depicts the standardized SVM for the prediction of the properties. 4.2. Decision tree A supervised learning technique used in ML, that constructs a tree- like model to make decisions based on a set of input variables [94] . It is commonly used for classification and regression tasks and has gained widespread popularity. In this method the data structure resembles a tree, having inner nodes and leaves. The \"inner nodes\" are the ones that have one or more branches leading to other nodes. Similarly, \"leaves\" are the nodes located at the end of a particular branch of the tree, and they do not have any outgoing branches. During the training phase of a Fig. 9. Model outcomes with bagging and boosting; (a) DT-bagging approach; (b) DT-boosting approach; (c) Modified RF approach; (d) SVR-bagging approach; (e) SVR- boosting approach. L. Alkhattabi and K. Arif Materials Today Communications 40 (2024) 109764 8 decision tree, each input variable is given a unique importance, and an \"inner node\" in the tree splits the input data into multiple classes using a function that is determined at this time. The decision tree algorithm generates the tree by minimizing a fitness function on a given dataset, identifying the optimal tree as illustrated in Fig. 7 [43] . In the absence of classes within the dataset, the algorithm adjusts by constructing a regression model for the dependent variable, taking into account different factors. At each division point in the tree, the algorithm eval- uates the disparity between expected and actual fitness function values, distributing multiple points to each variable in the dataset. When all variables exhibit equal errors at the split point, the algorithm selects the variable with the lowest fitness function values as the decisive split point. Iterating through this process, the algorithm systematically con- structs the optimal tree, ensuring a comprehensive evaluation of factors and minimizing errors in the model ’ s predictive capabilities [95] . 4.3. Random forest regression Researchers have taken an interest in the RF model because of its",
      "start_page": 6,
      "end_page": 8
    },
    {
      "title": "classification and regression methodology that is used for predicting the",
      "content": "mechanical properties of materials [96] . Shaqadan et al. [97] utilized the RF regression model to predict the compressive strength (CS) of concrete and noticed a reliable performance. Unlike DT, which produces only one tree, RF grows multiple trees to form a forest where different data subsets are randomly selected and distributed across each tree as demonstrated in Fig. 8 [97] . Every tree consists of data arranged in rows and columns with variable dimensions that can be defined. The devel- opment of every tree involves the following phases: 1. For each tree, a data frame is generated by selecting a random subset, constituting two-thirds of the entire dataset, through a technique called bagging. Predictor variables are then randomly chosen and used to split the nodes of the tree in the most precise manner possible. 2. The remaining data that was not selected is referred to as \"out-of-bag\" (OOB) data, which is used to evaluate the performance of each tree, which is known as the out-of-bag error. Following the estimation of the out-of-bag error for each tree, the errors from all trees are aggregated to determine the overall out-of-bag error rate. This is achieved by summing up the individual errors of every tree within the random forest model. 3. After each tree in the random forest algorithm generates its own regression model, the model selects a subset of trees based on the number of correct predictions, which are counted as 1, while incor- rect predictions are counted as 0. The trees with the highest number of votes are then chosen for the final model. The predictions made by these selected trees are combined to obtain the overall prediction for the random forest model. This approach of combining predictions from multiple models helps to improve the accuracy and robustness of the final prediction. 4.4. Hyper parameter tuning Choosing the right hyper parameters is vital for obtaining optimal performance when building ML models [54] . In this study, multiple parameter configurations for each algorithm are used based on previous literature [98 – 101] , as shown in Table 4 . This is done to improve the predictive accuracy of the models. Moreover, choosing the correct pa- rameters is crucial when developing non-linear models, and evaluating different combinations to find the optimal configuration for accurate and reliable performance can be a time-consuming process. Fig. 10. Model Validation by K-fold cross-validation algorithm.",
      "start_page": 8,
      "end_page": 8
    },
    {
      "title": "Table 5",
      "content": "Statistical measures. Equation of statistical indicator Acceptable range Reference R 2 = ∑ n i = 1 ( Y i − X i ) 2 ∑ n i = 1 ( Y i − X i ) 2 Close to 1 [102] RMSE = ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ ∑ n i = 1 ( P i − E i ) 2 N √ MAE < RMSE [103] MAE = 1 n ∑ n i = 1 | E i − P i | [104] NSE = 1 − ∑ n i = 1 ( E i − P i ) 2 ∑ n i = 1 ( E i − E i ) 2 Higher than 0.65 forvery good model RMSLE = ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ 1 n ∑ n i = 1 [ log ( P i + 1 )− log ( E i + 1 )] 2 √ Approaches 0 for a good model [102] RSE = ∑ n i = 1 ( E i − P i ) 2 ∑ n i = 1 ( E − P i ) 2 RRMSE ( % ) = 1 | e | ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ ∑ n i = 1 ( E i − P i ) 2 n √ x 100 For excellent model (0 – 10) %; goodmodel (11 – 20) % [104] n = data points, E i = Experimental data, P i = predicted data, Ei = averageexperiment values, Pi = average predicted values L. Alkhattabi and K. Arif Materials Today Communications 40 (2024) 109764 9",
      "start_page": 8,
      "end_page": 8
    },
    {
      "title": "5. Ensemble techniques using bagging and bossing",
      "content": "Ensemble algorithm is an effective way to improve the prediction accuracy of ML models. The technique of combining weaker prediction models or component sub-models is known as ensemble learning. It involves using multiple models to make predictions on a given dataset. Although these individual models may be less accurate when used alone. Thus, combining them can help minimize over-fitting issues associated with the training data. By aggregating the predictions of multiple models, the ensemble can benefit from the strengths of each model and produce a more reliable and accurate overall prediction. One of the most widely used ensemble algorithms is known as bagging, which utilizes the bootstrap resampling and aggregation procedures. In bagging, component models replace the original training set, and bootstrap tests are conducted up to the size of the training set. This introduces a level of randomness, allowing certain data points to be utilized multiple times in the final models. The insights drawn from bagging involve averaging the",
      "start_page": 9,
      "end_page": 9
    },
    {
      "title": "results obtained from all individual models, providing a robust and",
      "content": "aggregated prediction. Boosting, on the other hand, is an alternative method that assembles a cumulative model similar to bagging. It facil- itates the creation of a larger number of components, achieving enhanced accuracy compared to a single model. In this method the weighted averages of dependent sub-models are incorporated to opti- mize their contribution to the overall model, offering a sophisticated approach to improve predictive performance. Therefore, this study uti- lizes SVM, DT, and RF regression to forecast the resilient modulus of subgrade, and various hyper-parameter configurations were incorpo- rated to improve the models ’ accuracy. 5.1. Fine-tuning parameters for ensemble learners The parameters that need to be tuned may include the number of base models (or \"learners\") in the ensemble, the learning rate (which controls how quickly the model adapts to new data), and other signifi- cant features that have a substantial impact on the performance of in- dividual base models within the ensemble. In this study, bagging and boosting ensemble models with varying numbers of component sub- models (ranging from 1 to 20) were built for each learner. Correlation coefficients were employed to determine the best structures for each model. The findings revealed that the ensemble model with boosting demonstrated a higher correlation coefficient for prediction accuracy compared to the individual models, as shown in Fig. 9 . Furthermore, Fig. 9 (a) and Fig. 9 (b) present the outcomes of DT. In addition, Fig. 9 (c)",
      "start_page": 9,
      "end_page": 9
    },
    {
      "title": "and Figure (e) represents SVM models in the context of ensemble",
      "content": "models, while",
      "start_page": 9,
      "end_page": 9
    },
    {
      "title": "6. K-fold cross-validation approach",
      "content": "The k-fold cross-validation technique is often employed to overcome the bias of random sampling in training data. According to Kohavi ’ s research, ten-fold validation tests provide both reliable variance and reasonable computation time for validation of the models. In this study, the effectiveness of a classification model aimed at categorizing a specified number of data samples into ten distinct subgroups was thor- oughly assessed using stratified ten-fold cross-validation. This rigorous evaluation involved dividing the dataset into ten subsets, ensuring a balanced representation of each subgroup in both training and testing phases. During each of the ten iterations of model development and assessment, a fresh data subset was exclusively employed for testing, while the remaining subsets were utilized for training the model. As shown in Fig. 10 , the model was validated using the test subset, and the mean precision value obtained by ten models across ten validation it- erations was calculated to assess the accuracy of the method. 6.1. Statistical analysis for evaluating ML models Furthermore, statistical measurements are employed to analyze the performance, accuracy, and dependability of models. Therefore, a total of eight statistical gauges were employed to evaluate the performance of the finalized models. These indicators include Root Mean Squared Error (RMSE), Nash-Sutcliffe Efficiency (NSE), Root Mean Square Logarithmic Error (RMSLE), Root Squared Error (RSE), Mean Absolute Error (MAE), Performance Index (PI), Percentage of Relative Root Mean Square Error (RRMSE%), and Determination Coefficient (R 2 ). The Nash-Sutcliffe Ef- ficiency or, NSE, is a statistical metric that spans a range from negative infinity to one. A value of 1 signifies a complete alignment between the Fig. 11. DT outcomes; (a) train data; (b) train data discrepancies. Fig. 12. DT outcomes; (a) test set; (b) test set discrepancies. L. Alkhattabi and K. Arif Materials Today Communications 40 (2024) 109764 10",
      "start_page": 9,
      "end_page": 19
    }
  ],
  "processing_info": {
    "heuristic_used": true,
    "llm_used": false,
    "merge_strategy": "preference_based",
    "confidence": "high",
    "confidence_score": 0.93,
    "llm_error": "All API endpoints failed",
    "processing_time_seconds": 0.45,
    "paper_filename": "Paper1.pdf",
    "file_size_mb": 16.44
  },
  "statistics": {
    "total_pages": 20,
    "citations_count": 46,
    "section_count": 53,
    "abstract_length": 940,
    "keyword_count": 4
  }
}